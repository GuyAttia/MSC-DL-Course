{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrhUVnT34rCC"
   },
   "source": [
    "$$\n",
    "\\newcommand{\\mat}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\mattr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\matinv}[1]{\\boldsymbol {#1}^{-1}}\n",
    "\\newcommand{\\vec}[1]{\\boldsymbol {#1}}\n",
    "\\newcommand{\\vectr}[1]{\\boldsymbol {#1}^\\top}\n",
    "\\newcommand{\\rvar}[1]{\\mathrm {#1}}\n",
    "\\newcommand{\\rvec}[1]{\\boldsymbol{\\mathrm{#1}}}\n",
    "\\newcommand{\\diag}{\\mathop{\\mathrm {diag}}}\n",
    "\\newcommand{\\set}[1]{\\mathbb {#1}}\n",
    "\\newcommand{\\cset}[1]{\\mathcal{#1}}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "\\newcommand{\\pderiv}[2]{\\frac{\\partial #1}{\\partial #2}}\n",
    "\\newcommand{\\bb}[1]{\\boldsymbol{#1}}\n",
    "\\newcommand{\\E}[2][]{\\mathbb{E}_{#1}\\left[#2\\right]}\n",
    "\\newcommand{\\ip}[3]{\\left<#1,#2\\right>_{#3}}\n",
    "\\newcommand{\\given}[]{\\,\\middle\\vert\\,}\n",
    "\\newcommand{\\DKL}[2]{\\cset{D}_{\\text{KL}}\\left(#1\\,\\Vert\\, #2\\right)}\n",
    "\\newcommand{\\grad}[]{\\nabla}\n",
    "\\newcommand{\\norm}[1]{\\left\\lVert#1\\right\\rVert}\n",
    "$$\n",
    "\n",
    "# Part 3: Summary Questions\n",
    "<a id=part2></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiOzKbCk4rCH"
   },
   "source": [
    "This section contains summary questions about various topics from the course material.\n",
    "\n",
    "You can add your answers in new cells below the questions.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- Clearly mark where your answer begins, e.g. write \"**Answer:**\" in the beginning of your cell.\n",
    "- Provide a full explanation, even if the question doesn't explicitly state so. We will reduce points for partial explanations!\n",
    "- This notebook should be runnable from start to end without any errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3bA6Km24rCH"
   },
   "source": [
    "### CNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DlPheMzv4rCI"
   },
   "source": [
    "1. Explain the meaning of the term \"receptive field\" in the context of CNNs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cb3832_A4rCI"
   },
   "source": [
    "**Answer:**\n",
    "The receptive field is the region of the input space that a cnn feature is affected by. \n",
    "Basically, the size of the kernel the cnn layer operates on defines the receptive field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMjQdfDJ4rCJ"
   },
   "source": [
    "2. Explain and elaborate about three different ways to control the rate at which the receptive field grows from layer to layer. Compare them to each other in terms of how they combine input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yu4NaoU74rCJ"
   },
   "source": [
    "**Answer**: \n",
    "\n",
    "- Change the conv net depth- We explained above theat the kernel size of one layer controls the RF of the next layer. If we add more layers, the number of kernels the image will pass through is larger, what will cause the RF of the last layer to grow (same as for decreasing the dipth of the net).\n",
    "\n",
    "- Add diliation- when adding diliation to the kernel, it creates a bigger kernel with the same parameters number. for example, the receptive field of a 3x3 kernel with diliation of 2 has the same RF as a regular kernel of size 5x5.\n",
    "\n",
    "- Add stride- When adding a stride to a convolutional layer, there are more inputs which affect the output of the layer comparing to a general conv layer which changes by 1 (pixel for example) it location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQrnIYIW4rCK"
   },
   "source": [
    "3. Imagine a CNN with three convolutional layers, defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T06:58:56.041234Z",
     "iopub.status.busy": "2022-02-17T06:58:56.041025Z",
     "iopub.status.idle": "2022-02-17T06:58:56.706377Z",
     "shell.execute_reply": "2022-02-17T06:58:56.706377Z"
    },
    "id": "BKVuribi4rCL",
    "outputId": "d76fbb63-d763-4557-92e1-729dad121089"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 122, 122])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "cnn = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=4, out_channels=16, kernel_size=5, stride=2, padding=2),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(in_channels=16, out_channels=32, kernel_size=7, dilation=2, padding=3),\n",
    "    nn.ReLU(),\n",
    ")\n",
    "\n",
    "cnn(torch.rand(size=(1, 3, 1024, 1024), dtype=torch.float32)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7icvEgvJ4rCM"
   },
   "source": [
    "What is the size (spatial extent) of the receptive field of each \"pixel\" in the output tensor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "\n",
    "We will use the following recusive formula to compute the receptive field-\n",
    "$r_o = \\sum_{l=1}^{L}\\left(\\left({k_l-1}\\right)\\prod_{i=1}^{l-1}s_i\\right)+1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$=> r_0 = ((3-1)*1 + (2-1)*1*1 + (5-1)*2*1*1 + (2-1)*1*2*1*1 + (7*2-1 -1)*1*1*2*1*1) + 1 = 38$\n",
    "\n",
    "- The number of channels between layers and padding don't affect RF.\n",
    "- The diliation of the last layer causes the kernel to be of a size- 7*2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BWdhmawy4rCN"
   },
   "source": [
    "4. You have trained a CNN, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$, and $f_l(\\cdot;\\vec{\\theta}_l)$ is a convolutional layer (not including the activation function).\n",
    "\n",
    "  After hearing that residual networks can be made much deeper, you decide to change each layer in your network you used the following residual mapping instead $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)+\\vec{x}$, and re-train.\n",
    "\n",
    "  However, to your surprise, by visualizing the learned filters $\\vec{\\theta}_l$ you observe that the original network and the residual network produce completely different filters. Explain the reason for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhZ7jaRj4rCN"
   },
   "source": [
    "**Answer** Residual networks were desined in order to solve the issue of vanishing gradients in deep convolutional networks. As the depth of the cnn increases, the gradients in the deeper layers gets smaller and smaller and can eeven get to a situation the nn can't learn at all. When using the skip connection and propagating the input to the ouput of the conv layer, we enable the gradients to flow via this skip connection during the backpropgation phase. This causes the filters to be generated completely different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zVm5HtAN4rCO"
   },
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9-ragktq4rCO"
   },
   "source": [
    "1. Consider the following neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T06:58:56.706377Z",
     "iopub.status.busy": "2022-02-17T06:58:56.706377Z",
     "iopub.status.idle": "2022-02-17T06:58:56.722225Z",
     "shell.execute_reply": "2022-02-17T06:58:56.722225Z"
    },
    "id": "vXTzhbQu4rCO",
    "outputId": "68227e23-b227-4944-b53b-388a1969d462"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Dropout(p=0.1, inplace=False)\n",
       "  (3): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "p1, p2 = 0.1, 0.2\n",
    "nn.Sequential(\n",
    "    nn.Conv2d(in_channels=3, out_channels=4, kernel_size=3, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(p=p1),\n",
    "    nn.Dropout(p=p2),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7EvrMj--4rCP"
   },
   "source": [
    "If we want to replace the two consecutive dropout layers with a single one defined as follows:\n",
    "```python\n",
    "nn.Dropout(p=q)\n",
    "```\n",
    "what would the value of `q` need to be? Write an expression for `q` in terms of `p1` and `p2`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FpRXjMWS4rCP"
   },
   "source": [
    "**Answer:**\n",
    "The combined droput will be-\n",
    "$\\\\q = 1-(1-p1)*(1-p2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZ018Ivi4rCP"
   },
   "source": [
    "2. **True or false**: dropout must be placed only after the activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VgFRP-Bo4rCP"
   },
   "source": [
    "**Answer:**\n",
    "False: placing the dropout before or after the activation function doesn't change any result. The dropout layer purpose is to randomly remove a portion of the neurons in the layer. It doesn't backpropagated and doesn't affect the values of the activation function if it's applied before or after it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rfq_rjWe4rCQ"
   },
   "source": [
    "3. After applying dropout with a drop-probability of $p$, the activations are scaled by $1/(1-p)$. Prove that this scaling is required in order to maintain the value of each activation unchanged in expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OtluWJV44rCQ"
   },
   "source": [
    "**Answer**: \n",
    "\n",
    "The expectation of the activation after dropout layer with probability p-\n",
    "\n",
    "$E(activation) = p*0 + (1-p)*x = (1-p)x$ //(p*0- since the value of the output gets zeroed with probability p).\n",
    "\n",
    "By scaling the activations by 1/(1-p) we get that the expectations is-\n",
    "$E(activation) = (1-p)x * \\frac{1}{1-p} = x$\n",
    "\n",
    "which is the same as the expected value of a regular netwoek not using dropout.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85DMlCqh4rCQ"
   },
   "source": [
    "### Losses and Activation functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HMP2MfY4rCQ"
   },
   "source": [
    "1. You're training a an image classifier that, given an image, needs to classify it as either a dog (output 0) or a hotdog (output 1). Would you train this model with an L2 loss? if so, why? if not, demonstrate with a numerical example. What would you use instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_8qcYnc4rCR"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "No. MSE is not the right choice for classification problems since its doesn't produce a final set of values as the classification problem wishes to get.\n",
    "\n",
    "In order to get better and faster results we will use the Binary Cross Erntropy loss for this problem.\n",
    "\n",
    "** It is possible to use MSE as a loss in classification problem, but it is not the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgjpJ-wA4rCR"
   },
   "source": [
    "2. After months of research into the origins of climate change, you observe the following result:\n",
    "\n",
    "<center><img src=\"https://sparrowism.soc.srcf.net/home/piratesarecool4.gif\" /></center>\n",
    "\n",
    "You decide to train a cutting-edge deep neural network regression model, that will predict the global temperature based on the population of pirates in `N` locations around the globe.\n",
    "You define your model as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T06:58:56.722225Z",
     "iopub.status.busy": "2022-02-17T06:58:56.722225Z",
     "iopub.status.idle": "2022-02-17T06:58:56.737863Z",
     "shell.execute_reply": "2022-02-17T06:58:56.737863Z"
    },
    "id": "hp8j2ljX4rCR"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "N = 42  # number of known global pirate hot spots\n",
    "H = 128\n",
    "mlpirate = nn.Sequential(\n",
    "    nn.Linear(in_features=N, out_features=H),\n",
    "    nn.Sigmoid(),\n",
    "    *[\n",
    "        nn.Linear(in_features=H, out_features=H), nn.Sigmoid(),\n",
    "    ]*24,\n",
    "    nn.Linear(in_features=H, out_features=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jMiHKIaz4rCR"
   },
   "source": [
    "While training your model you notice that the loss reaches a plateau after only a few iterations.\n",
    "It seems that your model is no longer training.\n",
    "What is the most likely cause?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QYh1GMk94rCR"
   },
   "source": [
    "**Answer**: \n",
    "The most likley situation that caused this result is that the neural network was stuck in a local minimum.\n",
    "This local minimum is mainly caused by the Sigmoid function used in as activation.\n",
    "Because Sigmoid function gets produces values between 0 and 1, when it gets a very small value it will output a value close to 0.\n",
    "This will cause the training to get \"stuck\" during backprop since the gradients values are very small (vanishing gradients).\n",
    "Also, because of using only 1 feature, maybe the network has took it's maximum information regarding it's affect on the result, what can cause a plteau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FJvdJd-M4rCS"
   },
   "source": [
    "3. Referring to question 2 above: A friend suggests that if you replace the `sigmoid` activations with `tanh`, it will solve your problem. Is he correct? Explain why or why not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2x22RVL34rCS"
   },
   "source": [
    "**Answer**:\n",
    "Yes- as stated above, because of the values it produces, the Sigmoud function can cause negative and small values to \"dissapear\".\n",
    "TanH on the other hand outputs values between -1 and 1, what solves the Sigmoid issue and can help training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGgIq4ex4rCS"
   },
   "source": [
    "4. Regarding the ReLU activation, state whether the following sentences are **true or false** and explain:\n",
    "  1. In a model using exclusively ReLU activations, there can be no vanishing gradients.\n",
    "  1. The gradient of ReLU is linear with its input when the input is positive.\n",
    "  1. ReLU can cause \"dead\" neurons, i.e. activations that remain at a constant value of zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OVl57svQ4rCS"
   },
   "source": [
    "5. **Answer**: False- the ReLU function can cause vanishing gradients, the same way as explained above for Sigmoid.\n",
    "6. **Answer**: True- The ReLU function is linear on it's positive part, so when backpropagating through it we get a gradient linear to it's input.\n",
    "7. **Answer**: True- When getting a negative value, ReLU outputs 0. This causes it's output neurons to be turned off."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ceb1fdR4rCS"
   },
   "source": [
    "### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JG1e-bhn4rCS"
   },
   "source": [
    "1. Explain the difference between: stochastic gradient descent (SGD), mini-batch SGD and regular gradient descent (GD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8_Hui8ht4rCT"
   },
   "source": [
    "**Answer**:\n",
    "\n",
    "SGD- During training the algorigm updated the weights after every training example (samples are chosen randomly).\n",
    "\n",
    "Mini-batch SGD- During training the algorithm updates the weights after a given number of training examples (mini-bach number of samples).\n",
    "\n",
    "GD- During training the algorithm updates the weights only after going through all the traning examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gHpqrDZf4rCT"
   },
   "source": [
    "2. Regarding SGD and GD:\n",
    "  1. Provide at least two reasons for why SGD is used more often in practice compared to GD.\n",
    "  2. In what cases can GD not be used at all?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F4Nw6Xw4rCT"
   },
   "source": [
    "**Answer**: \n",
    "\n",
    "3.\n",
    "- In GD we calculate all the derivitives in on step what causes the calculation time get very slow.\n",
    "- Chances to overfit in SGD are lower since we pick a single point in random at each parameters update.\n",
    "4. When the dataset is too large there will not be enough memory to hold all the parameters and gradients calculation for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTlJWWit4rCT"
   },
   "source": [
    "3. You have trained a deep resnet to obtain SoTA results on ImageNet.\n",
    "While training using mini-batch SGD with a batch size of $B$, you noticed that your model converged to a loss value of $l_0$ within $n$ iterations (batches across all epochs) on average.\n",
    "Thanks to your amazing results, you secure funding for a new high-powered server with GPUs containing twice the amount of RAM.\n",
    "You're now considering to increase the mini-batch size from $B$ to $2B$.\n",
    "Would you expect the number of of iterations required to converge to $l_0$ to decrease or increase when using the new batch size? explain in detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0YUMDCk4rCT"
   },
   "source": [
    "**Answer**: We expect the number of iterations to decrease since at each iteration we see twice the number of examples. Therefore, the algorithm will converge to $l_0$ after ~1/2 of the iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUc0ANGe4rCT"
   },
   "source": [
    "4. For each of the following statements, state whether they're **true or false** and explain why.\n",
    "  1. When training a neural network with SGD, every epoch we perform an optimization step for each sample in our dataset.\n",
    "  1. Gradients obtained with SGD have less variance and lead to quicker convergence compared to GD.\n",
    "  1. SGD is less likely to get stuck in local minima, compared to GD.\n",
    "  1. Training  with SGD requires more memory than with GD.\n",
    "  1. Assuming appropriate learning rates, SGD is guaranteed to converge to a local minimum, while GD is guaranteed to converge to the global minimum.\n",
    "  1. Given a loss surface with a narrow ravine (high curvature in one direction): SGD with momentum will converge more quickly than Newton's method which doesn't have momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aV3OSg6V4rCU"
   },
   "source": [
    "5. **Answer**: True- As stated above, SGD updates the parameters for every training sample during every iteration.\n",
    "6. **Answer**: False- SGD gradients tend to have bigger variance compared to the gradients of GD. Because SGD cakculates the gradient for randomly chosen training example each time it will see very different gradient values compared to GD which calculated the mean gradients of all training examples each iteration.\n",
    "7. **Asnwer**: True- When updating the parameters after every training sample, the algorithm has more option go get out of local minima comparing to only one parameters update per epoch.\n",
    "8. **Answer**: False- GD requires more memory since it needs to hold the data for all gradients of all training exampls in each iteration.\n",
    "9. **Answer**: False- GD can converge to local minimum, while SGD can converge to global minimum. This is the more probable situation since the randomness of the SGD is more likely to get it out of local minimas compared to GD which is not random at all (GD must start from different stating point in each epoch to avoid local minima).\n",
    "10. **Answer**: True- Momentum gives big weight on the previous gradient directions. So if the surface has one drection only, momentum will cause the algorithm go bigger steps towards this direction in each iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEKNt8Bm4rCU"
   },
   "source": [
    "5. **Bonus** (we didn't discuss this at class):  We can use bi-level optimization in the context of deep learning, by embedding an optimization problem as a layer in the network.\n",
    "  **True or false**: In order to train such a network, the inner optimization problem must be solved with a descent based method (such as SGD, LBFGS, etc).\n",
    "  Provide a mathematical justification for your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTvZB57c4rCU"
   },
   "source": [
    "6. You have trained a neural network, where each layer $l$ is represented by the mapping $\\vec{y}_l=f_l(\\vec{x};\\vec{\\theta}_l)$ for some arbitrary parametrized functions $f_l(\\cdot;\\vec{\\theta}_l)$.\n",
    "  Unfortunately while trying to break the record for the world's deepest network, you discover that you are unable to train your network with more than $L$ layers.\n",
    "  1. Explain the concepts of \"vanishing gradients\", and \"exploding gradients\".\n",
    "  2. How can each of these problems be caused by increased depth?\n",
    "  3. Provide a numerical example demonstrating each.\n",
    "  4. Assuming your problem is either of these, how can you tell which of them it is without looking at the gradient tensor(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**:\n",
    "7. \"vanishig gradients\"- Happens espacially when the network is deep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. You wish to train the following 2-layer MLP for a binary classification task:\n",
    "  $$\n",
    "  \\hat{y}^{(i)} =\\mat{W}_2~ \\varphi(\\mat{W}_1 \\vec{x}^{(i)}+ \\vec{b}_1) + \\vec{b}_2\n",
    "  $$\n",
    "  Your wish to minimize the in-sample loss function is defined as\n",
    "  $$\n",
    "  L_{\\mathcal{S}} = \\frac{1}{N}\\sum_{i=1}^{N}\\ell(y^{(i)},\\hat{y}^{(i)}) + \\frac{\\lambda}{2}\\left(\\norm{\\mat{W}_1}_F^2 + \\norm{\\mat{W}_2}_F^2 \\right)\n",
    "  $$\n",
    "  Where the pointwise loss is binary cross-entropy:\n",
    "  $$\n",
    "  \\ell(y, \\hat{y}) =  - y \\log(\\hat{y}) - (1-y) \\log(1-\\hat{y})\n",
    "  $$\n",
    "  \n",
    "  Write an analytic expression for the derivative of the final loss $L_{\\mathcal{S}}$ w.r.t. each of the following tensors: $\\mat{W}_1$, $\\mat{W}_2$, $\\mat{b}_1$, $\\mat{b}_2$, $\\mat{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The derivative of a function $f(\\vec{x})$ at a point $\\vec{x}_0$ is\n",
    "  $$\n",
    "  f'(\\vec{x}_0)=\\lim_{\\Delta\\vec{x}\\to 0} \\frac{f(\\vec{x}_0+\\Delta\\vec{x})-f(\\vec{x}_0)}{\\Delta\\vec{x}}\n",
    "  $$\n",
    "  \n",
    "  1. Explain how this formula can be used in order to compute gradients of neural network parameters numerically, without automatic differentiation (AD).\n",
    "  \n",
    "  2. What are the drawbacks of this approach? List at least two drawbacks compared to AD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ac_mv0zFJx1g"
   },
   "source": [
    "**Answer**: \n",
    "\n",
    "3. This formula can be used instead of calculating the gradients analitically in backpropagation. It can be used when the AD can't handle the computation overload.\n",
    "\n",
    "4. This approach can be less accurate, since it doesn't uses chain rule as AD use to calculate complex deivatives.\n",
    "Also, it can be slower to compute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Given the following code snippet:\n",
    "  1. Write a short snippet that implements that calculates gradient of `loss` w.r.t. `W` and `b` using the approach of numerical gradients from the previous question.\n",
    "  2. Calculate the same derivatives with autograd.\n",
    "  3. Show, by calling `torch.allclose()` that your numerical gradient is close to autograd's gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T06:58:56.737863Z",
     "iopub.status.busy": "2022-02-17T06:58:56.737863Z",
     "iopub.status.idle": "2022-02-17T06:58:56.771943Z",
     "shell.execute_reply": "2022-02-17T06:58:56.771943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss=tensor(1.6421, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N, d = 100, 5\n",
    "dtype = torch.float64\n",
    "X = torch.rand(N, d, dtype=dtype)\n",
    "W, b = torch.rand(d, d, requires_grad=True, dtype=dtype), torch.rand(d, requires_grad=True, dtype=dtype)\n",
    "\n",
    "def foo(W, b):\n",
    "    return torch.mean(X @ W + b)\n",
    "\n",
    "loss = foo(W, b)\n",
    "print(f\"{loss=}\")\n",
    "\n",
    "# TODO: Calculate gradients numerically for W and b\n",
    "# grad_W =...\n",
    "# grad_b =...\n",
    "\n",
    "# TODO: Compare with autograd using torch.allclose()\n",
    "# autograd_W = ...\n",
    "# autograd_b = ...\n",
    "# assert torch.allclose(grad_W, autograd_W)\n",
    "# assert torch.allclose(grad_b, autograd_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Regarding word embeddings:\n",
    "  1. Explain this term and why it's used in the context of a language model.\n",
    "  \n",
    "  **Answer:**\n",
    "  Word embeddings is a learned representation for text where words that have the same meaning have a similar representation. In fact it's a class of techniques where individual words are represented as real-valued vectors in a predefined vector space. Each word is mapped to one vector and the vector values are learned in a way that resembles a neural network. There are different techniques for learning these representations, for example Embedding-Layer, Word2Vec and Glove.\n",
    "  A language model is the use of statistical and probabilistic techniques to determine the probability of a given sequence of words occurring in a sentence.\n",
    "  Language models are using in NLP applications in general and particularly ones that generate text as an output. One type of language models is the Neural Language Models, which make uses of neural networks and word embeddings.\n",
    "\n",
    "  1. Can a language model like the sentiment analysis example from the tutorials be trained without an embedding (i.e. trained directly on sequences of tokens)? If \n",
    "  yes, what would be the consequence for the trained model? if no, why not?\n",
    "  \n",
    "  **Answer:**\n",
    "  Technically, language models can be trained without an embedding. Word embeddings help in capturing the semantic and syntactic contexts of different words, and therefore probably will result with lower results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Considering the following snippet, explain:\n",
    "  1. What does `Y` contain? why this output shape?\n",
    "  \n",
    "  **Answer**\n",
    "  Y contain the actual vector representation of each token in the X n-dimentional tensor. Each vector length is 42000.\n",
    "  The output shape is the input shape with the addition of the vector length as the last layer\n",
    "\n",
    "  2. **Bonus**: How you would implement `nn.Embedding` yourself using only torch tensors. \n",
    "  \n",
    "  **Answer**\n",
    "  At the end the nn.Embedding module is a lookup table that stores the tokens representations. Probably, I would hold a torch tensor with two dimensions, the first with the number of embeddings as indices, and the second with the actual tokens representations for each index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-17T06:58:56.771943Z",
     "iopub.status.busy": "2022-02-17T06:58:56.771943Z",
     "iopub.status.idle": "2022-02-17T06:58:56.902941Z",
     "shell.execute_reply": "2022-02-17T06:58:56.902941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y.shape=torch.Size([5, 6, 7, 8, 42000])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "X = torch.randint(low=0, high=42, size=(5, 6, 7, 8))\n",
    "embedding = nn.Embedding(num_embeddings=42, embedding_dim=42000)\n",
    "Y = embedding(X)\n",
    "print(f\"{Y.shape=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Regarding truncated backpropagation through time (TBPTT) with a sequence length of S: State whether the following sentences are **true or false**, and explain.\n",
    "  1. TBPTT uses a modified version of the backpropagation algorithm.\n",
    "  \n",
    "  **Answer**\n",
    "  True. TBPTT, is a modified version of the BPTT training algorithm (which is a modified version of the backpropagation algorithm) for recurrent neural networks where the sequence is processed one timestep at a time and periodically the BPTT update is performed back for a fixed number of timesteps.\n",
    "\n",
    "  2. To implement TBPTT we only need to limit the length of the sequence provided to the model to length S.\n",
    "  \n",
    "  **Answer**\n",
    "  False. To implement TBPTT we shouldn't limit the length of the input sequence. The algorithm processes the sequence one timestep at a time and update periodically using the BPTT algotithm for a fixed number of timesteps.\n",
    "  We need to define two key parameters for TBPTT:\n",
    "  - k1: The number of forward-pass timesteps between updates. \n",
    "  - k2: The number of timesteps to which to apply BPTT.\n",
    "\n",
    "  3. TBPTT allows the model to learn relations between input that are at most S timesteps apart.\n",
    "\n",
    "  **Answer**\n",
    "  False. Because we can apply the BPTT update every k1 timesteps, we can define S (k2) to be low enough to still learn relations between different \"time-batches\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. In tutorial 5 we learned how to use attention to perform alignment between a source and target sequence in machine translation.\n",
    "  1. Explain qualitatively what the addition of the attention mechanism between the encoder and decoder does to the hidden states that the encoder and decoder each learn to generate (for their language). How are these hidden states different from the model without attention?\n",
    "  \n",
    "  2. After learning that self-attention is gaining popularity thanks to the transformer models, you decide to change the model from the tutorial: instead of the queries being equal to the decoder hidden states, you use self-attention, so that the keys, queries and values are all equal to the encoder's hidden states (with learned projections, like in the tutorial..). What influence do you expect this will have on the learned hidden states?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OuhTjwFpD5-o"
   },
   "source": [
    "**Answer**: \n",
    "\n",
    "In a regular encoder decoder mechanism the encoder encodes the input sequence to one fixed length context vector which is used by the decoder.\n",
    "This produces a limitaition (especialy as the input sequence gets longer) to the ability of the decoder to decode based on this fixed lenght context vector.\n",
    "When adding attention mechanism between the encoder and the decoder, each output vector of the decoder is based now on it's own context vector, which is affected by the output vectors of the input sequence and by **the hidden states of the decoder in of the previous step**. This is how the hidden states of the decoder areaffected by the attention mechanism.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. As we have seen, a variational autoencoder's loss is comprised of a reconstruction term and  a KL-divergence term. While training your VAE, you accidentally forgot to include the KL-divergence term.\n",
    "What would be the qualitative effect of this on:\n",
    "\n",
    "  1. Images reconstructed by the model during training ($x\\to z \\to x'$)?\n",
    "  \n",
    "  **Answer**\n",
    "  The VAE loss is comprised of both the reconstruction term that makes the encoding-decoding scheme efficient, and the KL-divergence term that can be interpreted as a regularizer which prevents the inference network from copying x into z. \n",
    "  Therefore, if we forgot to include the KL-divergence term, our model can be led into a sub-optimal solution where the decoder ignores the inferred latent code z, and suffer from an issue known as posterior collapse where the encoder become independent of x and the inference network produces uninformative latent variables.\n",
    "  Due that, the images reconstructed by the model during training probably will show great results.\n",
    "\n",
    "  1. Images generated by the model ($z \\to x'$)?\n",
    "\n",
    "  **Answer**\n",
    "  As explained above, the decoder ignores the inferred latent code z, so the generated images should suffer from bad results.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding VAEs, state whether each of the following statements is **true or false**, and explain:\n",
    "  1. The latent-space distribution generated by the model for a specific input image is $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "  \n",
    "  **Answer**\n",
    "  False. In our case we did choose the latent-space distribution to be $\\mathcal{N}(\\vec{0},\\vec{I})$, but it surely not a must.\n",
    "  As explained in class, for example it can be $x \\sim \\mathcal{N}(\\mu, \\Sigma)$\n",
    "\n",
    "  2. If we feed the same image to the encoder multiple times, then decode each result, we'll get the same reconstruction.\n",
    "\n",
    "  **Answer**\n",
    "  True. At the end VAE forward function is sequential operations on different layers, if we didn't update any weights between the different inputs and only pass it forward we should get the same results (reconstruction).\n",
    "  \n",
    "  3. Since the real VAE loss term is intractable, what we actually minimize instead is it's upper bound, in the hope that the bound is tight.\n",
    "\n",
    "  **Answer**\n",
    "  False. We are maximizing the variational lower bound on the data likelihood which is the reconstructed term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Regarding GANs, state whether each of the following statements is **true or false**, and explain:\n",
    "  1. Ideally, we want the generator's loss to be low, and the discriminator's loss to be high so that it's fooled well by the generator.\n",
    "\n",
    "  **Answer**\n",
    "  True. GAN's loss consist of two parts, the expected conditional log-likelihood for real and generated data, while the discriminator output the probability that the sample is real. \n",
    "  \n",
    "  $ V(D,G) = \\mathbb{E}_{x \\sim p(x)} \\left[ \\log D(x) \\right] + \\mathbb{E}_{z\\sim q(z)} \\left[\\log(1 - D\\left(G(z)\\right)) \\right] $\n",
    "\n",
    "  The generator can't directly affect the $\\log(D(x))$ term in the function, so, for the generator, minimizing the loss is equivalent to minimizing $\\log(1 - D(G(z)))$.\n",
    "  The discriminator wants to correctly distinguish real and fake samples, so we want to maximize it's loss.\n",
    "  \n",
    "  2. It's crucial to backpropagate into the generator when training the discriminator.\n",
    "\n",
    "  **Answer**\n",
    "  False. When training the discriminator we freeze the generator and backpropogate only the discriminator.\n",
    "\n",
    "  3. To generate a new image, we can sample a latent-space vector from $\\mathcal{N}(\\vec{0},\\vec{I})$.\n",
    "\n",
    "  **Answer**\n",
    "  True. GAN is an implicit model, means it does not try to estimate $𝑃(𝑋)$ explicitly like VAE (not even $𝑃(𝑋|𝑧)$. When we want to generate a new image we only need to use the generator and provide him with a random noise as an input, this random noise vecotr can be sampled from the described latent-space distribution.\n",
    "\n",
    "  4. It can be beneficial for training the generator if the discriminator is trained for a few epochs first, so that it's output isn't arbitrary.\n",
    "\n",
    "  **Answer**\n",
    "  True. Altough studies still didn't prove it, the basic idea is correct. If you can't train a classifier to tell the difference between real and generated data even for the initial random generator output, you can't get the GAN training started.\n",
    "\n",
    "  5. If the generator is generating plausible images and the discriminator reaches a stable state where it has 50% accuracy (for both image types), training the generator more will further improve the generated images.\n",
    "\n",
    "  **Answer**\n",
    "  False. In that case the discriminator is no longer contribute to the system and along with that the generator can't improve due to the bad feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection and Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What is the diffrence between IoU and Dice score? what's the diffrance between IoU and mAP?\n",
    "    shortly explain when would you use what evaluation?\n",
    "\n",
    "  **Answer**\n",
    "  IoU - Intersection over Union, is the rate of overlap area over the union area. Meaning, what % of the predicted and ground-true area is covered by the prediction mask.\n",
    "  Dice score - is 2 * the area of overlap divided by the total number of pixels in both images.\n",
    "  The IoU and Dice are very similar and even positivly correlated. Dice counts twich the true positive while IoU counts true positives once in both the numerator and denominator.The difference comes when taking the average score over a set of inferences. In general, the IoU metric tends to penalize single instances of bad classification more than Dice score quantitatively even when they can both agree that this one instance is bad. The IoU metric tends to have a \"squaring\" effect on the errors relative to the Dice score. So the Dice score tends to measure something closer to average performance, while the IoU score measures something closer to the worst case performance. \n",
    "\n",
    "  mAP - Mean average precision, when there are several classes in the segmentation problem, the mAP calculate the mean AP (average precision) among them, where AP is the integral under the Pricision-Recall curve for the relevant class.\n",
    "\n",
    "  We would use mAP when we don't want to set specific weights on some classes.\n",
    "  We would use IoU when we want to give more weight for larger errors and Dice otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. regarding of YOLO and mask-r-CNN, witch one is one stage detector? describe the RPN outputs and the YOLO output, adress how the network produce the output and the shapes of each output.\n",
    "\n",
    "  **Answer**\n",
    "  A one-stage detector, requires only a single pass through the neural network and predicts all the bounding boxes in one go, between both, YOLO is a one stage detector.\n",
    "  RPN outputs - Region Proposal Network takes an image of any size as input and outputs a set of rectangular object proposals each with an objectness score. \n",
    "  YOLO output - YOLO has 24 convolutional layers followed by 2 fully connected layers. Some convolution layers use 1 × 1 reduction layers alternatively to reduce the depth of the features maps. For the last convolution layer, it outputs a tensor with shape (7, 7, 1024). The tensor is then flattened. Using 2 fully connected layers as a form of linear regression, it outputs 7×7×30 parameters and then reshapes to (7, 7, 30), i.e. 2 boundary box predictions per location.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
